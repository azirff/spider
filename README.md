<h1>Python爬虫汇总<br> </h1><p>这是我从学习爬虫开始到现在以来，我爬取的网站代码，从简单到困难的都有，学习是一个漫长的过程，坚持下去，别给自己留下遗憾，<a href="https://github.com/azirff/spider" target="_blank">所有项目代码链接：GitHub - azirff/spide。</a></p><h2>豆瓣爬取（解决cookie登录）<br> </h2><hr><p>借鉴文档：<a href="https://blog.csdn.net/qq_16209077/article/details/80012080" target="_blank">Python爬虫--使用cookies登录豆瓣网 - wonder - CSDN博客</a></p><p>关键词：cookie，panands，xpath，header</p><p>这个项目适合新手作为入门学习，比较简单。</p><h2>新浪新闻爬取（selenium）<br> </h2><hr><p>借鉴文档：<a href="https://www.jianshu.com/p/eb3df224045c?utm_campaign=haruki&amp;utm_content=note&amp;utm_medium=reader_share&amp;utm_source=qq" target="_blank">使用selenium+requests登录网页并持久化cookie - 简书</a></p><p>关键词：selenium，WebDriverWait，firefox，datatime</p><p>相当与使用selenium模拟浏览器操作可以避免一些复杂的反爬手段，缺点就是效率不高</p><h2>正方教务系统爬虫</h2><hr><p>借鉴文档：<a href="https://blog.csdn.net/beat_the_world/article/details/45621673" target="_blank">python爬虫实战之模拟正方教务系统登录查询成绩 - Crazy-biubiubiu - CSDN博客</a></p><p>                 <a href="https://blog.csdn.net/nghuyong/article/details/51622888" target="_blank">python爬虫正方教务系统 - nghuyong的博客 - CSDN博客</a></p><p>关键词：简单验证码,cookie,requests，asp.net</p><p>主要包含了带有验证码的模拟登录获取cookie，再使用cookie来requests.post到成绩数据，由于asp.net网页需要post一个viewstate，所以要找到它的值然后post上去，得到成绩表单后再通过BeautifulSoup来取得成绩，最后经过pandas处理后存入表单xls中</p><h2>拉勾网爬虫<br> </h2><hr><p>借鉴文档：<a href="https://github.com/wfgydbu/PythonCrawlers/blob/master/lagou.py" target="_blank">PythonCrawlers/lagou.py at master · wfgydbu/PythonCrawlers · GitHub</a></p><p>关键词：sqlite3，cookie，json</p><p>一开始想用selenium来直接获取到页面源代码，但是这样并不能锻炼自己，所以我想通过抓包来自己发送post请求得到数据。我一开始看到抓来的数据包里的cookie一大堆不知道从那儿来的，但请教了一位前辈后才得知第一次发送搜素请求会返回你一个cookie，而cookie中的值才是关键所以要分析原请求看那些变量是cookie中的值在请求的cookie中就需要添加进去其他的都是无关紧要的，由于拉勾网的一个请求只能用10次所以在第十次时要重新请求一下，最后保存到数据库（sqlite3需自己安装）</p><hr><h2>图片写真网站爬虫</h2><p>借鉴文档：<a href="https://blog.csdn.net/qq_37143745/article/details/80996707" target="_blank">Scrapy框架流程图解析 - 田田&amp;味道的博客 - CSDN博客</a></p><p><a href="https://blog.csdn.net/heheyanyanjun/article/details/79199378" target="_blank">                 scrapy调用parse()中使用yield引发对yield的分析 - heheyanyanjun的专栏 - CSDN博客</a></p><p><a href="https://www.cnblogs.com/attitudeY/p/7078559.html" target="_blank">                 通过scrapy内置的ImagePipeline下载图片到本地、并提取本地保存地址 - Young_G - 博客园</a></p><p>关键词：scrapy,selenium,imagepipeline</p><p>这是我第一次学习使用scrapy框架写爬虫，我要爬的网站是一个国外的图片网站，所以需要翻墙，当我使用抓包工具查看时发现里面的图片数据都被加密了，由于我目前还不知道如何破解该加密，所以我只能通过添加selenium中间件来获取已经渲染好的图片url，通过不断的学习我了解到了scrapy框架的运行流程，并从中学习到了我python的知识盲区yield，生成器generator的概念，最后使用scrapy的内置imagepipeline成功下载到图片</p><hr><h2><b>bilibili弹幕爬虫</b></h2><p>借鉴文档：<a href="https://blog.csdn.net/loner_fang/article/details/81022164" target="_blank">scrapy框架流程图</a></p><p>关键词：scrapy,mysql,fiddler</p><p>丢了一段时间没有学感觉忘了好多，不过没关系慢慢把之前忘的知识捡起来，这次通过fiddler抓包分析出弹幕数据的链接地址，然后通过scrapy框架来编写bilibili弹幕爬虫，并且连接了MySQL数据库，最后将爬取到的弹幕数据在pipeline中存入数据库</p><hr><h2>boss直聘爬虫</h2><p>借鉴文档：<a href="https://www.cnblogs.com/BigFishFly/p/6380046.html" target="_blank">Python爬虫进阶四之PySpider的用法 - 知行Lee - 博客园</a></p><p>                 <a href="https://blog.csdn.net/xiao_yi_xiao/article/details/101835176" target="_blank">常见反爬机制</a></p><p>                 <a href="https://blog.csdn.net/cool_soup29/article/details/94401469" target="_blank">selenium被服务器检测解决方法</a></p><p>关键词：pyspider,mysql,selenium,token</p><p>这次使用pyspider框架爬boss直聘感觉自己又学到了很多知识，首先pyspider是真难装，查了好多资料改了好多文件才装上，之后在控制台中pyspider all又发现用不了,网上查了一下发现必须要多开几个才能启动（这框架真装着真心累），在编写boss直聘pyspyder爬虫时遇到的反爬问题主要是cookie的获取和爬虫的速度控制，速度的控制用time.sleep()方法就可以解决了，而cookie的获取就没这么容易了，cookie中有一个zp_token直到现在还不知道它是怎么生成的，网上查阅资料也没找到很好的办法，于是我就想到了用selenium来获取cookie，但是没有想到selenium被boss监测到了，于是我又更改了chromewebdriver的配置将他变为开发者模式最终成功获取到cookie，当我以为离成功只有一步之遥的时候，我又卡在了一个问题上，那就是当我编译时是可以爬到数据的而启动程序只能爬到几条数据，又用fiddler抓包分析发现原来这个cookie是动态的，每个cookie最多爬4条数据，我又在index_page（）中加了个方法让其每爬3条链接更新一次cookie，最后终于成功爬到所有数据，算了下大概日均一两万条数据。在使用pyspider框架过后自我感觉pyspder的优点在于代码编写简单，有web界面，调试也很方便，缺点也很明显安装好了还要改配置，无法立刻删除项目，过于封装。</p><hr><h2><b>全站爬取拉勾网</b></h2><p>借鉴文档：<a href="https://www.cnblogs.com/ChenGuangW/p/12261676.html" target="_blank">拉勾网cookie问题</a></p><p><a href="https://www.cnblogs.com/zhenchoafeng/p/10863726.html" target="_blank">                 scrapy中setting文件设置参数问题</a></p><p><a href="https://blog.csdn.net/qq_27297393/article/details/86094916" target="_blank">                 scrapy重定向问题</a></p><p><a href="https://blog.csdn.net/qq_23392341/article/details/77773653" target="_blank">                 重复url被过滤的问题</a></p><p>关键词：scrapy，mysql，代理ip，cookie</p><p>一开始在编写代码之前就犯了一个关键性错误，误以为拉勾的cookie与boss一样请求一次只能使用5次，实际上拉勾中cookie含有时间戳设置，大概在请求后的5秒内cookie都有效，所以要在scrapy的setting中将并发请求数设置调小，由于我是在中间件中设置的cookie如果并发请求太大的话就会导致之前先设置好cookie的过期，只有后设置的一部分cookie有效。同时还有url的重定向问题与url重复被过滤的问题经过查阅资料全都解决，总共爬取物联网相关岗位7000多条。</p>
